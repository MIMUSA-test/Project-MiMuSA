{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_explorerVersion7 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdColumn_to_list_converter(df):\n",
    "    df_list = df.values.tolist() #produces list of lists\n",
    "    proper_list = [item for sublist in df_list for item in sublist] #a single list\n",
    "    return proper_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment Num</th>\n",
       "      <th>Multi</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Effective  but   too-tepid  biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>If   you   sometimes   like   to    go   to  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Emerges   as   something  rare  ,    an   i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The  film     provides   some   great  insigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Offers    that   rare  combination   of    en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  Sentiment Num  Multi  \\\n",
       "0   Neutral              0      0   \n",
       "1  Positive              1      1   \n",
       "2  Positive              1      2   \n",
       "3   Neutral              0      0   \n",
       "4  Positive              1      2   \n",
       "\n",
       "                                                Text  \n",
       "0                 Effective  but   too-tepid  biopic  \n",
       "1   If   you   sometimes   like   to    go   to  ...  \n",
       "2     Emerges   as   something  rare  ,    an   i...  \n",
       "3   The  film     provides   some   great  insigh...  \n",
       "4   Offers    that   rare  combination   of    en...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv('test-readynew.csv')  #import reviews\n",
    "df = pd.read_csv('sg-transport-1115-clean.csv')  #import reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text-original'] = df['Text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Punctuations From Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def newtext(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('/\\s\\s+/g', ' ') # replace multiple spaces with a single space\n",
    "    text = text.replace(\":)\",\"happy\")\n",
    "    text = text.replace(\":(\",\"sad\")\n",
    "    text = re.sub ('\\s+', ' ', text)\n",
    "    text = re.sub('@[^\\s]+','',text)  # delete the username\n",
    "    text = re.sub('&[^\\s]+','',text)\n",
    "    text = re.sub('#[^\\s]+','',text)\n",
    "    text = re.sub('\".*?\"', '', text)  # delete anything in quotation marks\n",
    "    text = re.sub('http[s]?://\\S+', '', text) # delete urls\n",
    "    text = text.replace(\"as well as\",\"and\")\n",
    "    text = text.replace(\"as well\",\"also\")\n",
    "    text = re.sub(\"\\S*@\\S*\\s?\",'',text)   # delete email address\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')  # Clean up all \"\\n\"\n",
    "    \n",
    "    text = re.sub(r\"\"\"\n",
    "               [,.;@#?!&$]+  # Accept one or more copies of punctuation\n",
    "               \\ *           # plus zero or more copies of a space,\n",
    "               \"\"\",\n",
    "               \"\",          # and replace it with no space\n",
    "               text, flags=re.VERBOSE)\n",
    "    text= re.sub(' +', ' ', text)\n",
    "    #text= re.sub(':', '', text)\n",
    "    text= re.sub(\"[:']\", '', text)\n",
    "    #text = re.sub ('\\s+', '', text)\n",
    "    return text.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newtext_fullstop(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('/\\s\\s+/g', ' ') # replace multiple spaces with a single space\n",
    "    text = text.replace(\":)\",\"happy\")\n",
    "    text = text.replace(\":(\",\"sad\")\n",
    "    text = re.sub ('\\s+', ' ', text)\n",
    "    text = re.sub('@[^\\s]+','',text)  # delete the username\n",
    "    text = re.sub('&[^\\s]+','',text)\n",
    "    text = re.sub('#[^\\s]+','',text)\n",
    "    text = re.sub('\".*?\"', '', text)  # delete anything in quotation marks\n",
    "    text = re.sub('http[s]?://\\S+', '', text) # delete urls\n",
    "    text = text.replace(\"as well as\",\"and\")\n",
    "    text = text.replace(\"as well\",\"also\")\n",
    "    text = re.sub(\"\\S*@\\S*\\s?\",'',text)   # delete email address\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '')  # Clean up all \"\\n\"\n",
    "    \n",
    "    text = re.sub(r\"\"\"\n",
    "               [,;@#&$]+  # Accept one or more copies of punctuation\n",
    "               \\ *           # plus zero or more copies of a space,\n",
    "               \"\"\",\n",
    "               \"\",          # and replace it with no space\n",
    "               text, flags=re.VERBOSE)\n",
    "    text = text.replace('.', ' .') #specially added to maintain fullstop\n",
    "    text = text.replace('?', ' ?') #specially added to maintain question mark\n",
    "    text = text.replace('!', ' !') #specially added to maintain exclamation mark\n",
    "    text= re.sub(' +', ' ', text)\n",
    "    #text= re.sub(':', '', text)\n",
    "    text= re.sub(\"[:']\", '', text)\n",
    "    #text = re.sub ('\\s+', '', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text_with_fullstop\"] = df['Text'].apply(lambda text: newtext_fullstop(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Text\"] = df['Text'].apply(lambda text: newtext(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment Num</th>\n",
       "      <th>Multi</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text-original</th>\n",
       "      <th>Text_with_fullstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>Effective  but   too-tepid  biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>If   you   sometimes   like   to    go   to  ...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>emerges as something rare an issue movie that ...</td>\n",
       "      <td>Emerges   as   something  rare  ,    an   i...</td>\n",
       "      <td>emerges as something rare an issue movie that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the film provides some great insight into the ...</td>\n",
       "      <td>The  film     provides   some   great  insigh...</td>\n",
       "      <td>the film provides some great insight into the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>offers that rare combination of entertainment ...</td>\n",
       "      <td>Offers    that   rare  combination   of    en...</td>\n",
       "      <td>offers that rare combination of entertainment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>an imaginative comedy\\/thriller</td>\n",
       "      <td>An   imaginative   comedy\\/thriller  .</td>\n",
       "      <td>an imaginative comedy\\/thriller .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-lrb- a -rrb- rare beautiful film</td>\n",
       "      <td>-LRB-   A  -RRB-   rare   ,   beautiful  fil...</td>\n",
       "      <td>-lrb- a -rrb- rare beautiful film .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-lrb- an -rrb- hilarious romantic comedy</td>\n",
       "      <td>-LRB-   An  -RRB-    hilarious   romantic  co...</td>\n",
       "      <td>-lrb- an -rrb- hilarious romantic comedy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>never -lrb- sinks -rrb- into exploitation</td>\n",
       "      <td>Never   -LRB-   sinks  -RRB-   into  exploit...</td>\n",
       "      <td>never -lrb- sinks -rrb- into exploitation .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-lrb- u -rrb- nrelentingly stupid</td>\n",
       "      <td>-LRB-   U  -RRB-    nrelentingly  stupid  .</td>\n",
       "      <td>-lrb- u -rrb- nrelentingly stupid .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2210 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment Num  Multi                                               Text  \\\n",
       "0                 0      0                     effective but too-tepid biopic   \n",
       "1                 1      1  if you sometimes like to go to the movies to h...   \n",
       "2                 1      2  emerges as something rare an issue movie that ...   \n",
       "3                 0      0  the film provides some great insight into the ...   \n",
       "4                 1      2  offers that rare combination of entertainment ...   \n",
       "...             ...    ...                                                ...   \n",
       "2205              1      1                   an imaginative comedy\\/thriller    \n",
       "2206              1      2                 -lrb- a -rrb- rare beautiful film    \n",
       "2207              1      2          -lrb- an -rrb- hilarious romantic comedy    \n",
       "2208              1      1         never -lrb- sinks -rrb- into exploitation    \n",
       "2209             -1     -1                 -lrb- u -rrb- nrelentingly stupid    \n",
       "\n",
       "                                          Text-original  \\\n",
       "0                    Effective  but   too-tepid  biopic   \n",
       "1      If   you   sometimes   like   to    go   to  ...   \n",
       "2        Emerges   as   something  rare  ,    an   i...   \n",
       "3      The  film     provides   some   great  insigh...   \n",
       "4      Offers    that   rare  combination   of    en...   \n",
       "...                                                 ...   \n",
       "2205             An   imaginative   comedy\\/thriller  .   \n",
       "2206    -LRB-   A  -RRB-   rare   ,   beautiful  fil...   \n",
       "2207   -LRB-   An  -RRB-    hilarious   romantic  co...   \n",
       "2208    Never   -LRB-   sinks  -RRB-   into  exploit...   \n",
       "2209        -LRB-   U  -RRB-    nrelentingly  stupid  .   \n",
       "\n",
       "                                     Text_with_fullstop  \n",
       "0                        effective but too-tepid biopic  \n",
       "1     if you sometimes like to go to the movies to h...  \n",
       "2     emerges as something rare an issue movie that ...  \n",
       "3     the film provides some great insight into the ...  \n",
       "4     offers that rare combination of entertainment ...  \n",
       "...                                                 ...  \n",
       "2205                  an imaginative comedy\\/thriller .  \n",
       "2206                -lrb- a -rrb- rare beautiful film .  \n",
       "2207         -lrb- an -rrb- hilarious romantic comedy .  \n",
       "2208        never -lrb- sinks -rrb- into exploitation .  \n",
       "2209                -lrb- u -rrb- nrelentingly stupid .  \n",
       "\n",
       "[2210 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Using Prof Wang's Standard English Dictionary Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarities Found\"] = df['Text'].apply(lambda text: findPolarity(' '.join(text.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count\"] = df['Polarities Found'].apply(lambda scores: countPolarity(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Prof Wang Standard English Only'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prof Wang Standard English Only': 0.5678733031674208}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614</td>\n",
       "      <td>164</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>237</td>\n",
       "      <td>158</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>909</td>\n",
       "      <td>389</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       1    0   -1\n",
       "Predicted               \n",
       "1          614  164  242\n",
       "0           58   67   96\n",
       "-1         237  158  574\n",
       "All        909  389  912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[-2:], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 : Using Prof Wang's Standard el + Prof Wang Singlish Dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarities Found\"] = df['Text'].apply(lambda text: findPolarity1(' '.join(text.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count\"] = df['Polarities Found'].apply(lambda scores: countPolarity1(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Prof Wang Standard English + Prof Wang Singlish'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prof Wang Standard English Only': 0.5678733031674208,\n",
       " 'Prof Wang Standard English + Prof Wang Singlish': 0.5678733031674208}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>614</td>\n",
       "      <td>164</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>67</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>237</td>\n",
       "      <td>158</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>909</td>\n",
       "      <td>389</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       1    0   -1\n",
       "Predicted               \n",
       "1          614  164  242\n",
       "0           58   67   96\n",
       "-1         237  158  574\n",
       "All        909  389  912"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[-2:], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Combined Standard EL + Combined Singlish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarities Found\"] = df['Text'].apply(lambda text: findPolarity2(' '.join(text.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count\"] = df['Polarities Found'].apply(lambda scores: countPolarity2(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prof Wang Standard English Only': 0.5678733031674208,\n",
       " 'Prof Wang Standard English + Prof Wang Singlish': 0.5678733031674208,\n",
       " 'Combined Standard English + Combined Singlish': 0.5678733031674208}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>612</td>\n",
       "      <td>162</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>67</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>240</td>\n",
       "      <td>160</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>909</td>\n",
       "      <td>389</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       1    0   -1\n",
       "Predicted               \n",
       "1          612  162  242\n",
       "0           57   67   94\n",
       "-1         240  160  576\n",
       "All        909  389  912"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[-2:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment Num</th>\n",
       "      <th>Multi</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text-original</th>\n",
       "      <th>Text_with_fullstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>Effective  but   too-tepid  biopic</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>If   you   sometimes   like   to    go   to  ...</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>emerges as something rare an issue movie that ...</td>\n",
       "      <td>Emerges   as   something  rare  ,    an   i...</td>\n",
       "      <td>emerges as something rare an issue movie that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the film provides some great insight into the ...</td>\n",
       "      <td>The  film     provides   some   great  insigh...</td>\n",
       "      <td>the film provides some great insight into the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>offers that rare combination of entertainment ...</td>\n",
       "      <td>Offers    that   rare  combination   of    en...</td>\n",
       "      <td>offers that rare combination of entertainment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>an imaginative comedy\\/thriller</td>\n",
       "      <td>An   imaginative   comedy\\/thriller  .</td>\n",
       "      <td>an imaginative comedy\\/thriller .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-lrb- a -rrb- rare beautiful film</td>\n",
       "      <td>-LRB-   A  -RRB-   rare   ,   beautiful  fil...</td>\n",
       "      <td>-lrb- a -rrb- rare beautiful film .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-lrb- an -rrb- hilarious romantic comedy</td>\n",
       "      <td>-LRB-   An  -RRB-    hilarious   romantic  co...</td>\n",
       "      <td>-lrb- an -rrb- hilarious romantic comedy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>never -lrb- sinks -rrb- into exploitation</td>\n",
       "      <td>Never   -LRB-   sinks  -RRB-   into  exploit...</td>\n",
       "      <td>never -lrb- sinks -rrb- into exploitation .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-lrb- u -rrb- nrelentingly stupid</td>\n",
       "      <td>-LRB-   U  -RRB-    nrelentingly  stupid  .</td>\n",
       "      <td>-lrb- u -rrb- nrelentingly stupid .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2210 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment  Sentiment Num  Multi  \\\n",
       "0      Neutral              0      0   \n",
       "1     Positive              1      1   \n",
       "2     Positive              1      2   \n",
       "3      Neutral              0      0   \n",
       "4     Positive              1      2   \n",
       "...        ...            ...    ...   \n",
       "2205  Positive              1      1   \n",
       "2206  Positive              1      2   \n",
       "2207  Positive              1      2   \n",
       "2208  Positive              1      1   \n",
       "2209  Negative             -1     -1   \n",
       "\n",
       "                                                   Text  \\\n",
       "0                        effective but too-tepid biopic   \n",
       "1     if you sometimes like to go to the movies to h...   \n",
       "2     emerges as something rare an issue movie that ...   \n",
       "3     the film provides some great insight into the ...   \n",
       "4     offers that rare combination of entertainment ...   \n",
       "...                                                 ...   \n",
       "2205                   an imaginative comedy\\/thriller    \n",
       "2206                 -lrb- a -rrb- rare beautiful film    \n",
       "2207          -lrb- an -rrb- hilarious romantic comedy    \n",
       "2208         never -lrb- sinks -rrb- into exploitation    \n",
       "2209                 -lrb- u -rrb- nrelentingly stupid    \n",
       "\n",
       "                                          Text-original  \\\n",
       "0                    Effective  but   too-tepid  biopic   \n",
       "1      If   you   sometimes   like   to    go   to  ...   \n",
       "2        Emerges   as   something  rare  ,    an   i...   \n",
       "3      The  film     provides   some   great  insigh...   \n",
       "4      Offers    that   rare  combination   of    en...   \n",
       "...                                                 ...   \n",
       "2205             An   imaginative   comedy\\/thriller  .   \n",
       "2206    -LRB-   A  -RRB-   rare   ,   beautiful  fil...   \n",
       "2207   -LRB-   An  -RRB-    hilarious   romantic  co...   \n",
       "2208    Never   -LRB-   sinks  -RRB-   into  exploit...   \n",
       "2209        -LRB-   U  -RRB-    nrelentingly  stupid  .   \n",
       "\n",
       "                                     Text_with_fullstop  \n",
       "0                        effective but too-tepid biopic  \n",
       "1     if you sometimes like to go to the movies to h...  \n",
       "2     emerges as something rare an issue movie that ...  \n",
       "3     the film provides some great insight into the ...  \n",
       "4     offers that rare combination of entertainment ...  \n",
       "...                                                 ...  \n",
       "2205                  an imaginative comedy\\/thriller .  \n",
       "2206                -lrb- a -rrb- rare beautiful film .  \n",
       "2207         -lrb- an -rrb- hilarious romantic comedy .  \n",
       "2208        never -lrb- sinks -rrb- into exploitation .  \n",
       "2209                -lrb- u -rrb- nrelentingly stupid .  \n",
       "\n",
       "[2210 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Combined Standard EL + Combined Singlish + Transport Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarities Found\"] = df['Text'].apply(lambda text: findPolarity3(' '.join(text.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count\"] = df['Polarities Found'].apply(lambda scores: countPolarity3(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prof Wang Standard English Only': 0.5678733031674208,\n",
       " 'Prof Wang Standard English + Prof Wang Singlish': 0.5678733031674208,\n",
       " 'Combined Standard English + Combined Singlish': 0.5678733031674208,\n",
       " 'Combined Standard English + Combined Singlish + Transport Domain': 0.567420814479638}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>599</td>\n",
       "      <td>159</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>63</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>254</td>\n",
       "      <td>167</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>909</td>\n",
       "      <td>389</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       1    0   -1\n",
       "Predicted               \n",
       "1          599  159  229\n",
       "0           56   63   91\n",
       "-1         254  167  592\n",
       "All        909  389  912"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[-2:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['Polarities Found'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={\"Polarity Count\": \"Polarity Count after Transport Domain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Combined Standard EL + Combined Singlish + Transport Domain + Negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Polarities Found\"] = df['Text_with_fullstop'].apply(lambda text: findPolarity4(' '.join(text.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count\"] = df['Polarities Found'].apply(lambda scores: countPolarity4(scores, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain + Negation'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prof Wang Standard English Only': 0.5678733031674208,\n",
       " 'Prof Wang Standard English + Prof Wang Singlish': 0.5678733031674208,\n",
       " 'Combined Standard English + Combined Singlish': 0.5678733031674208,\n",
       " 'Combined Standard English + Combined Singlish + Transport Domain': 0.567420814479638,\n",
       " 'Combined Standard English + Combined Singlish + Transport Domain + Negation': 0.5710407239819004}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>598</td>\n",
       "      <td>157</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>63</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>255</td>\n",
       "      <td>169</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>909</td>\n",
       "      <td>389</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       1    0   -1\n",
       "Predicted               \n",
       "1          598  157  220\n",
       "0           56   63   91\n",
       "-1         255  169  601\n",
       "All        909  389  912"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"checking.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[-2:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={\"Polarity Count\": \"Polarity Count after Negation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wrongly_labelled_negation = df[df['Polarity Count after Negation'] != df['Sentiment Num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wrongly_labelled_negation.to_csv('wrongly_labelled_negation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wrongly_labelled_negation_vs_transport = df_wrongly_labelled_negation[df_wrongly_labelled_negation['Polarity Count after Negation'] != df_wrongly_labelled_negation['Polarity Count after Transport Domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wrongly_labelled_negation_vs_transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wrongly_labelled_negation_vs_transport_correct = df_wrongly_labelled_negation_vs_transport[df_wrongly_labelled_negation_vs_transport['Sentiment Num'] == df_wrongly_labelled_negation_vs_transport['Polarity Count after Transport Domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wrongly_labelled_negation_vs_transport_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wrongly_labelled_negation_vs_transport_correct.to_csv('transport_correct_label_negation_wrong.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Combined Standard EL + Combined Singlish + Transport Domain + Negation + Too Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarities Found\"] = df['Text'].apply(lambda text: findPolarity4_too(' '.join(text.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count\"] = df['Polarities Found'].apply(lambda scores: countPolarity4(scores, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain + Negation + Too Handling'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6.1: Combined Standard EL + Combined Singlish + Transport Domain + Negation + Too Handling + Like Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarities Found\"] = df['Text'].apply(lambda text: findPolarity4_too_like(' '.join(text.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count\"] = df['Polarities Found'].apply(lambda scores: countPolarity4(scores, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain + Negation + Too Handling + Like Handling'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6.2: Combined Standard EL + Combined Singlish + Transport Domain + Negation + Too Handling + Like Handling + Question mark Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qn_mark(original_text, polarity):\n",
    "    fivewoneh=['what','why','who','where','when','how', 'What','Why','Who','Where','When','How']\n",
    "    if '?' in original_text:\n",
    "        original_text = original_text.strip()\n",
    "        if original_text.split(\" \")[0] not in fivewoneh:\n",
    "            polarity=-1\n",
    "    else:\n",
    "        polarity=polarity\n",
    "    return polarity\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count\"] = df.apply(lambda a: qn_mark(a['Text-original'],a['Polarity Count']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain + Negation + Too Handling + Like Handling + Qn Mark Handling'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Combined Standard EL + Combined Singlish + Transport Domain + Negation + Too Handling + Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sarcasm?\"] = df['Polarities Found'].apply(lambda row: recognise_sarcasm(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.loc[(df['Sarcasm?'] != 0), 'Polarity Count'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain + Nagation + Too Handling + Like Handling + Sarcasm'] = accuracy_score(df[\"Sentiment Num\"], df[\"Polarity Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasm_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcasm_df = sarcasm_df.rename(columns={'Polarity Count': 'Sarcasm Polarity Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sarcasm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Combined Standard EL + Combined Singlish + Transport Domain + Negation + Too Handling + Sarcasm + Adversative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"Polarities Found\"] = df['Text'].apply(lambda text: findPolarity5(' '.join(text.split())))\n",
    "df[\"Adversative Polarity\"] = df['Polarities Found'].apply(lambda scores: countPolarity5(scores, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flip(sarcasm,polarity_count):\n",
    "#     if sarcasm==-1:\n",
    "#         if polarity_count>0:\n",
    "#             return polarity_count*(-1)\n",
    "#         else:\n",
    "#             return polarity_count\n",
    "#     elif sarcasm==0:\n",
    "#         return polarity_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversative_present(polarity_list):\n",
    "    if (8 in polarity_list) or (-8 in polarity_list):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# label presence of adversative\n",
    "df['Adversative Present?']=df['Polarities Found'].apply(lambda pl:adversative_present(pl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_p_after_adversative(present,polaritys, polaritya):\n",
    "    if present==1:\n",
    "        return polaritya\n",
    "    elif present==0:\n",
    "        return polaritys\n",
    "\n",
    "df['Polarity Count-after Adversative'] = df.apply(lambda x: update_p_after_adversative(x['Adversative Present?'],x['Polarity Count'],x['Adversative Polarity']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Polarity Count-after Adversative\"] = df.apply(lambda a: qn_mark(a['Text-original'],a['Polarity Count-after Adversative']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "df['Polarity Count-after Adversative'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain + Negation + Too Handling + Like Handling + Sarcasm + Adversative'] = accuracy_score(adversative_df[\"Sentiment Num\"], adversative_df[\"Polarity Count-after Adversative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count-after Adversative'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Combined Standard EL + Combined Singlish + Transport Domain + Negation + Too Handling + Sarcasm + Adversative +  Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df[\"Emoji Score\"] = adversative_df['Text'].apply(lambda x: find_emoji(x))\n",
    "adversative_df.loc[(adversative_df['Polarity Count-after Adversative'] == 0), 'Polarity Count-after Adversative'] = adversative_df['Emoji Score'] #emoji handling only when 0 is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adversative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for checking\n",
    "adversative_df['Polarity Count-after Adversative'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain + Negation + Too Handling + Like Handling + Sarcasm + Adversative+ emoji'] = accuracy_score(adversative_df[\"Sentiment Num\"], adversative_df[\"Polarity Count-after Adversative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count-after Adversative'],df[\"Sentiment Num\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]\n",
    "df_confusion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Combined Standard EL + Combined Singlish + Transport Domain + Negation + Too Handling + Sarcasm + Adversative + Emoji + Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df[\"Polarities Found\"] = adversative_df['Text'].apply(lambda text: findPolarity6(' '.join(text.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df['Polarity Count-multi'] = adversative_df.apply(lambda scores: multi_value(scores['Polarities Found'],scores['Text'], scores['Polarity Count-after Adversative'], 5), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df[\"Polarity Count-multi\"] = adversative_df.apply(lambda a: qn_mark(a['Text-original'],a['Polarity Count-multi']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df # the last column gives us more information on the strength polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for checking\n",
    "adversative_df['Polarity Count-multi'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def new_multi(value):\n",
    "    if 0<value<=0.5:\n",
    "        valuenew=1\n",
    "    elif value==0:\n",
    "        valuenew=0\n",
    "    elif 1>=value>0.5:\n",
    "        valuenew=2\n",
    "    elif -0.5<=value<0:\n",
    "        valuenew=-1\n",
    "    elif -1<=value<-0.5:\n",
    "        valuenew=-2\n",
    "    return valuenew\n",
    "\n",
    "adversative_df['Polarity Count-multi']=adversative_df['Polarity Count-multi'].apply(new_multi)\n",
    "# adversative_df['Multi']=adversative_df['Multi'].apply(new_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_dict['Combined Standard English + Combined Singlish + Transport Domain + Negation + Too Handling + Like Handling + Sarcasm + Adversative+ Emoji + Multi'] = accuracy_score(adversative_df[\"Multi\"], adversative_df[\"Polarity Count-multi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(df['Polarity Count-multi'],df[\"Multi\"] , rownames=['Predicted'], colnames=['Actual'], margins= True)\n",
    "labels = [2, 1, 0, -1, -2]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "df_confusion.loc['All'] = df_confusion.loc[2] + df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1] + df_confusion.loc[-2]\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversative_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for checking\n",
    "adversative_df['Polarity Count-multi'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following for checking\n",
    "adversative_df.to_csv('Results-lexiconbased-23Julytest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for adversative since multi is in another ipynb\n",
    "df_confusion = pd.crosstab(adversative_df['Sentiment Num'],adversative_df[\"Polarity Count-after Adversative\"] , rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "labels = [1, 0, -1]\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"columns\")\n",
    "df_confusion = df_confusion.reindex(labels, axis=\"rows\")\n",
    "# df_confusion.loc['All'] = df_confusion.loc[1] + df_confusion.loc[0] + df_confusion.loc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised confusion matrix\n",
    "df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
    "df_conf_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.gray_r):\n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(df_confusion.index.name)\n",
    "    plt.xlabel(df_confusion.columns.name)\n",
    "\n",
    "plot_confusion_matrix(df_confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot normalized confusion matrix\n",
    "\n",
    "plot_confusion_matrix(df_conf_norm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(adversative_df['Sentiment Num'], adversative_df['Polarity Count-after Adversative'], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(adversative_df['Sentiment Num'], adversative_df['Polarity Count-after Adversative'], average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(adversative_df['Sentiment Num'], adversative_df['Polarity Count-after Adversative'], average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 12: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shuffle the data\n",
    "\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=df[:229]\n",
    "# print(df1)\n",
    "# df1.to_csv('df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2=df[229:458]\n",
    "# print(df2)\n",
    "# df2.to_csv('df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3=df[458:687]\n",
    "# print(df3)\n",
    "# df3.to_csv('df3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4=df[687:916]\n",
    "# print(df4)\n",
    "# df4.to_csv('df4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df5=df[916:]\n",
    "# print(df5)\n",
    "# df5.to_csv('df5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun the model on each df to test if the accuracy is stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13: Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='Sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['allnegative']=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# supposed our model predict all neutral, benchmark\n",
    "print(accuracy_score(df[\"Sentiment Num\"], df[\"allnegative\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ccd176210e4982d80f84cccb1b18685c0aca505e3b9a80370970fa9d5c54634"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
