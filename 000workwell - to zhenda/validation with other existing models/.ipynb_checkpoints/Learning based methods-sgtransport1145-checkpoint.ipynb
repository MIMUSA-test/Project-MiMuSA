{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits to Professor Wang's ML Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_0PVZsoU18gr",
    "outputId": "6674cd1a-2d5c-4bd7-f16e-38d5ae54c0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1062, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment Num</th>\n",
       "      <th>Multi</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@smrtsg  Fault Again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@smrtsg I'm an overseas Singaporean &amp;amp; foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@hangloon @mrbrown @LTAsg @SMRT_Singapore @SB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@NymeriusLXXXVII @smrtsg What are they fighti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@NymeriusLXXXVII @smrtsg What are they fighti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@SBSTransit_Ltd hi. I left a bag on the bus y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@SBSTransit_Ltd In the morning $1.43 is deduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>@SBSTransit_Ltd public transport sucks, coe p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@SBSTransit_Ltd strangely why still allow bus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>@SBSTransit_Ltd Why isn't there any staff dir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment  Sentiment Num  Multi  \\\n",
       "0  Negative             -1     -1   \n",
       "1  Negative             -1     -1   \n",
       "2  Negative             -1     -1   \n",
       "3  Negative             -1     -1   \n",
       "4  Negative             -1     -1   \n",
       "5  Negative             -1     -1   \n",
       "6  Negative             -1     -1   \n",
       "7  Negative             -1     -2   \n",
       "8  Negative             -1     -1   \n",
       "9  Negative             -1     -1   \n",
       "\n",
       "                                                Text  \n",
       "0                               @smrtsg  Fault Again  \n",
       "1  @smrtsg I'm an overseas Singaporean &amp; foun...  \n",
       "2   @hangloon @mrbrown @LTAsg @SMRT_Singapore @SB...  \n",
       "3   @NymeriusLXXXVII @smrtsg What are they fighti...  \n",
       "4   @NymeriusLXXXVII @smrtsg What are they fighti...  \n",
       "5   @SBSTransit_Ltd hi. I left a bag on the bus y...  \n",
       "6   @SBSTransit_Ltd In the morning $1.43 is deduc...  \n",
       "7   @SBSTransit_Ltd public transport sucks, coe p...  \n",
       "8   @SBSTransit_Ltd strangely why still allow bus...  \n",
       "9   @SBSTransit_Ltd Why isn't there any staff dir...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "from datetime import datetime\n",
    "begin = datetime.now()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('sg-transport-1115-clean.csv')#sgtransport1145.csv')\n",
    "\n",
    "# check data\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DswR-sJ418gu"
   },
   "outputs": [],
   "source": [
    "# basic pre-processing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(review):\n",
    "    review = \" \".join([stemmer.stem(w.lower()) for w in word_tokenize(re.sub('[^a-zA-Z]+', ' ', review.replace(\"<br />\", \"\"))) if not w in stop_words])\n",
    "    return review\n",
    "\n",
    "data['review_clean'] = data.apply(lambda x: preprocess(x['Text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v12wjKXi18gv",
    "outputId": "e889405b-50b7-4452-f4ec-83191ccf5772"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment Num</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>ComfortDelGro investigating after MaxiCab driv...</td>\n",
       "      <td>-1</td>\n",
       "      <td>comfortdelgro investig maxicab driver allegedl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>No choice lol...this nasi lemak very nice one ...</td>\n",
       "      <td>1</td>\n",
       "      <td>no choic lol nasi lemak nice one also hungri m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>i still cant get over the comfortdelgro at the...</td>\n",
       "      <td>1</td>\n",
       "      <td>still cant get comfortdelgro back fml lah free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Urine, stool in our bodies are somewhat uncomf...</td>\n",
       "      <td>-1</td>\n",
       "      <td>urin stool bodi somewhat uncomfort ever go mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>He cannot tahan lah what to do...pee in his pa...</td>\n",
       "      <td>1</td>\n",
       "      <td>he tahan lah pee pant huh all taxi driver must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Unacceptable, frustrating process in handling ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>unaccept frustrat process handl individu custo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Negative</td>\n",
       "      <td>ComfortDelgro cabby begs for mercy after being...</td>\n",
       "      <td>-1</td>\n",
       "      <td>comfortdelgro cabbi beg merci fine nea smoke t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Negative</td>\n",
       "      <td>They employ all these foreigners (malaysians) ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>they employ foreign malaysian care carri ball ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@comadad @MayorofLondon @SadiqKhan @ComfortDel...</td>\n",
       "      <td>-1</td>\n",
       "      <td>comadad mayoroflondon sadiqkhan comfortdelgro ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Positive</td>\n",
       "      <td>@AdamEkeen Could do with comfortdelgro giving ...</td>\n",
       "      <td>1</td>\n",
       "      <td>adamekeen could comfortdelgro give nat nice ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Sentiment                                               Text  \\\n",
       "0           0  Negative  ComfortDelGro investigating after MaxiCab driv...   \n",
       "1           1  Positive  No choice lol...this nasi lemak very nice one ...   \n",
       "2           2  Positive  i still cant get over the comfortdelgro at the...   \n",
       "3           3  Negative  Urine, stool in our bodies are somewhat uncomf...   \n",
       "4           4  Positive  He cannot tahan lah what to do...pee in his pa...   \n",
       "5           5  Negative  Unacceptable, frustrating process in handling ...   \n",
       "6           6  Negative  ComfortDelgro cabby begs for mercy after being...   \n",
       "7           7  Negative  They employ all these foreigners (malaysians) ...   \n",
       "8           8  Negative  @comadad @MayorofLondon @SadiqKhan @ComfortDel...   \n",
       "9           9  Positive  @AdamEkeen Could do with comfortdelgro giving ...   \n",
       "\n",
       "   Sentiment Num                                       review_clean  \n",
       "0             -1  comfortdelgro investig maxicab driver allegedl...  \n",
       "1              1  no choic lol nasi lemak nice one also hungri m...  \n",
       "2              1  still cant get comfortdelgro back fml lah free...  \n",
       "3             -1  urin stool bodi somewhat uncomfort ever go mus...  \n",
       "4              1  he tahan lah pee pant huh all taxi driver must...  \n",
       "5             -1  unaccept frustrat process handl individu custo...  \n",
       "6             -1  comfortdelgro cabbi beg merci fine nea smoke t...  \n",
       "7             -1  they employ foreign malaysian care carri ball ...  \n",
       "8             -1  comadad mayoroflondon sadiqkhan comfortdelgro ...  \n",
       "9              1  adamekeen could comfortdelgro give nat nice ne...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFmOEtoO18gv"
   },
   "source": [
    "### Split dataset to training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Hh8P1cZ418gv"
   },
   "outputs": [],
   "source": [
    "# split dataset to training and test dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_train, data_test, y_train, y_test = train_test_split(data['review_clean'], data['Sentiment'], \n",
    "                                                          test_size = 0.25, random_state = 2020, stratify = data['Sentiment'])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_counts = vectorizer.fit_transform(data_train)\n",
    "test_counts = vectorizer.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm9steah18gw"
   },
   "source": [
    "### Model Fitting\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pBNzSgWy18gw",
    "outputId": "25f701a1-7746-48b9-cdfd-2de562130959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy:\n",
      "0.6153846153846154\n",
      "Confusion Matrix:\n",
      "[[102  38  27]\n",
      " [ 26  71  11]\n",
      " [  6   2   3]]\n",
      "F1 Score:\n",
      "0.5857365304825299\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_counts, y_train)\n",
    "lr_pred = lr.predict(test_counts)\n",
    "print('Logistic Regression')\n",
    "print('Accuracy:')\n",
    "print(lr.score(test_counts, y_test))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(lr_pred, y_test))\n",
    "print('F1 Score:')\n",
    "print(f1_score(y_test, lr_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhjw51Pl18gy"
   },
   "source": [
    "### Model Fitting\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Bv5YIt5M18gz",
    "outputId": "24500a3e-9a7f-45c4-b888-c05a97132f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Accuracy:\n",
      "0.6328671328671329\n",
      "Confusion Matrix:\n",
      "[[116  46  30]\n",
      " [ 14  63   9]\n",
      " [  4   2   2]]\n",
      "F1 Score:\n",
      "0.5933700203621057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(train_counts, y_train)\n",
    "nb_pred = nb.predict(test_counts)\n",
    "print('Naive Bayes')\n",
    "print('Accuracy:')\n",
    "print(nb.score(test_counts, y_test))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(nb_pred, y_test))\n",
    "print('F1 Score:')\n",
    "print(f1_score(y_test, nb_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIRBPjQ418gz"
   },
   "source": [
    " ### Model Fitting - SVM\n",
    "### Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CGmV9ADr18gz",
    "outputId": "570f2d37-d48f-4aaa-8b98-c2e1b6cc5e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Accuracy:\n",
      "0.5699300699300699\n",
      "Confusion Matrix:\n",
      "[[89 36 25]\n",
      " [34 68 10]\n",
      " [11  7  6]]\n",
      "F1 Score:\n",
      "0.5568189284152535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "start=datetime.now()\n",
    "svm = LinearSVC()\n",
    "\n",
    "svm.fit(train_counts, y_train)\n",
    "svm_pred = svm.predict(test_counts)\n",
    "print('SVM')\n",
    "print('Accuracy:')\n",
    "print(svm.score(test_counts, y_test))\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(svm_pred, y_test))\n",
    "print('F1 Score:')\n",
    "print(f1_score(y_test, svm_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j_2D4NZR18gz",
    "outputId": "138d786b-f44d-4371-d0e4-3d2bb6ec8ac4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858, 3094)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4eLH4sxD18g2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Learning based methods (Transport).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
